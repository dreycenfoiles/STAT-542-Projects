{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import timeit\n",
    "import scipy\n",
    "import glmnet_python\n",
    "from glmnet import glmnet\n",
    "from glmnetPredict import glmnetPredict\n",
    "from glmnetCoef import glmnetCoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://liangfgithub.github.io/Data/Ames_data.csv\")\n",
    "testID = pd.read_csv(\n",
    "    'https://liangfgithub.github.io/Data/project1_testIDs.dat',delim_whitespace=' ',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_convert(frame):\n",
    "    # We may want to normalize data as well \n",
    "    for col in frame:\n",
    "        try:\n",
    "            frame[col] = pd.to_numeric(frame[col])\n",
    "        except:\n",
    "            frame[col] = pd.factorize(frame[col])[0]\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def get_split(frame, index):\n",
    "\n",
    "    frame = frame.drop('Garage_Yr_Blt', axis=1)\n",
    "\n",
    "    num_rows = np.arange(len(frame))\n",
    "\n",
    "    test_index = testID.iloc[:,index]\n",
    "    train_index = np.array([i for i in num_rows if i not in test_index])\n",
    "\n",
    "    xtest = numeric_convert(frame.iloc[test_index,1:-1].copy())\n",
    "    xtrain = numeric_convert(frame.iloc[train_index,1:-1].copy())\n",
    "\n",
    "    # convert to log to get better model\n",
    "    ytest = np.log(frame.iloc[test_index,-1].copy())\n",
    "    ytrain = np.log(frame.iloc[train_index,-1].copy())\n",
    "\n",
    "    return xtrain,xtest,ytrain,ytest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, cols):\n",
    "    for col in cols:\n",
    "        df = df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cols = ['PID', 'Garage_Yr_Blt', 'Street', 'Utilities', 'Condition_2', 'Roof_Matl', 'Heating', 'Pool_QC', 'Misc_Feature', 'Low_Qual_Fin_SF', 'Pool_Area', 'Longitude','Latitude']\n",
    "PID = df['PID']\n",
    "# Set up data for use with scikit-learn\n",
    "frame = clean_data(df, bad_cols)\n",
    "cvsplits = []\n",
    "num_rows = np.arange(len(frame))\n",
    "for index in range(0,10):\n",
    "    test_index = testID.iloc[:,index]\n",
    "    train_index = np.array([i for i in num_rows if i not in test_index])\n",
    "    cvsplits.append((train_index, test_index.values))\n",
    "\n",
    "x = numeric_convert(frame.iloc[:,:-1].copy())\n",
    "for c in x:\n",
    "    x[c] = x[c] / np.max(np.abs(x[c]))\n",
    "\n",
    "# convert to log to get better model\n",
    "y = np.log(frame.iloc[:,-1].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rmse = []\n",
    "lr_times = []\n",
    "lr_models = []\n",
    "lr_lambda = []\n",
    "lambdas = np.exp(np.linspace(-1,-8,80))\n",
    "for i in range(0,10):\n",
    "    lr = Lasso()\n",
    "    start = timeit.default_timer()\n",
    "    lr.fit(x.iloc[cvsplits[i][0]], y[cvsplits[i][0]])\n",
    "    stop = timeit.default_timer()\n",
    "    yhat = lr.predict(x.iloc[cvsplits[i][1]])\n",
    "    ytest = y[cvsplits[i][1]]\n",
    "    rf_models.append(rf)\n",
    "    rf_times.append(stop - start)\n",
    "    rf_rmse.append(np.sqrt(np.mean((yhat - ytest)**2)))\n",
    "    print(f'Split {i} RMSE: {rf_rmse[-1]}, runtime: {rf_times[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0 RMSE: 0.1458660492361605, runtime: 0.34390075400006026\n",
      "Split 1 RMSE: 0.14875871404828894, runtime: 0.34559665600045264\n",
      "Split 2 RMSE: 0.16894699503168575, runtime: 0.21791181000025972\n",
      "Split 3 RMSE: 0.16504560614278746, runtime: 0.2648320230000536\n",
      "Split 4 RMSE: 0.15623868857774714, runtime: 0.33875934699972277\n",
      "Split 5 RMSE: 0.14582337257907863, runtime: 0.30205251400002453\n",
      "Split 6 RMSE: 0.14875736370380688, runtime: 0.1928231970005072\n",
      "Split 7 RMSE: 0.16888216163770614, runtime: 0.2252748540004177\n",
      "Split 8 RMSE: 0.164849583012185, runtime: 0.24972158899981878\n",
      "Split 9 RMSE: 0.15623020650410496, runtime: 0.2389675040003567\n"
     ]
    }
   ],
   "source": [
    "lr_rmse = []\n",
    "lr_times = []\n",
    "lr_lambdas = []\n",
    "lr_models = []\n",
    "for i in range(0,10):\n",
    "    start = timeit.default_timer()\n",
    "    ytrain = y.iloc[cvsplits[i][0]].to_numpy()\n",
    "    fit = glmnet(x = x.iloc[cvsplits[i][0]].to_numpy(), y=ytrain, family = 'gaussian')\n",
    "    lambdau = fit['lambdau']\n",
    "    fold_rmse = []\n",
    "    for l in lambdau:\n",
    "        ytrainhat = (glmnetPredict(fit, x.iloc[cvsplits[i][0]].to_numpy(), s = scipy.float64([l]))).flatten()\n",
    "        fold_rmse.append(np.sqrt(np.mean((ytrainhat - ytrain)**2)))\n",
    "    best_idx = np.where(fold_rmse == np.min(np.abs(fold_rmse)))[0][0]\n",
    "    lr_lambdas.append(lambdau[best_idx])\n",
    "    stop = timeit.default_timer()\n",
    "    yhat = glmnetPredict(fit, x.iloc[cvsplits[i][1]].to_numpy(), s = scipy.float64([lr_lambdas[-1]])).flatten()\n",
    "    ytest = y[cvsplits[i][1]]\n",
    "    lr_models.append(fit)\n",
    "    lr_times.append(stop - start)\n",
    "    lr_rmse.append(np.sqrt(np.mean((yhat - ytest)**2)))\n",
    "    print(f'Split {i} RMSE: {lr_rmse[-1]}, runtime: {lr_times[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00018263318833249426,\n",
       " 0.00018263318833249426,\n",
       " 0.00018263318833249426,\n",
       " 0.00018263318833249426,\n",
       " 0.00018263318833249426,\n",
       " 0.00018263318833249426,\n",
       " 0.00018263318833249426,\n",
       " 0.00018263318833249426,\n",
       " 0.00018263318833249426,\n",
       " 0.00018263318833249426]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       218001.477644\n",
       "1       116608.410042\n",
       "2        84212.068569\n",
       "3       283076.667240\n",
       "4       196584.601125\n",
       "            ...      \n",
       "2925    151017.143889\n",
       "2926    147737.891234\n",
       "2927    116037.325249\n",
       "2928    187085.115343\n",
       "2929    229838.453524\n",
       "Name: Sale_Price, Length: 2930, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx = np.where(lr_rmse == np.min(lr_rmse))[0][0]\n",
    "lr_best = lr_models[best_idx]\n",
    "yhat_best = np.exp(glmnetPredict(lr_best, x.to_numpy(), s=scipy.float64([lr_lambdas[best_idx]]))).flatten()\n",
    "pd.Series(yhat_best, name='Sale_Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={'PID': PID, 'Sale_Price': pd.Series(yhat_best, name='Sale_Price')}).to_csv('mysubmission1.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0 RMSE: 0.08560174009149243, runtime: 2.360530913999355\n",
      "Split 1 RMSE: 0.08755284967027353, runtime: 2.3281028270002935\n",
      "Split 2 RMSE: 0.09702514716671658, runtime: 2.334553627000787\n",
      "Split 3 RMSE: 0.09286057760848333, runtime: 2.434900249000748\n",
      "Split 4 RMSE: 0.0901684012156606, runtime: 2.4509402490002685\n",
      "Split 5 RMSE: 0.08661063964214978, runtime: 2.432449457000075\n",
      "Split 6 RMSE: 0.08533644085192464, runtime: 2.36360153699934\n",
      "Split 7 RMSE: 0.09695785526464452, runtime: 2.3423530660002143\n",
      "Split 8 RMSE: 0.0923036871921028, runtime: 2.435029413999473\n",
      "Split 9 RMSE: 0.08794964719264137, runtime: 2.422240172999409\n"
     ]
    }
   ],
   "source": [
    "rf_rmse = []\n",
    "rf_times = []\n",
    "rf_models = []\n",
    "for i in range(0,10):\n",
    "    rf = RandomForestRegressor(criterion='squared_error')\n",
    "    start = timeit.default_timer()\n",
    "    rf.fit(x.iloc[cvsplits[i][0]], y[cvsplits[i][0]])\n",
    "    stop = timeit.default_timer()\n",
    "    yhat = rf.predict(x.iloc[cvsplits[i][1]])\n",
    "    ytest = y[cvsplits[i][1]]\n",
    "    rf_models.append(rf)\n",
    "    rf_times.append(stop - start)\n",
    "    rf_rmse.append(np.sqrt(np.mean((yhat - ytest)**2)))\n",
    "    print(f'Split {i} RMSE: {rf_rmse[-1]}, runtime: {rf_times[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       196490.049809\n",
       "1       128850.577556\n",
       "2       155984.480263\n",
       "3       220791.345294\n",
       "4       184100.554639\n",
       "            ...      \n",
       "2925    143394.537198\n",
       "2926    132253.127864\n",
       "2927    129521.132480\n",
       "2928    172499.626035\n",
       "2929    204174.396405\n",
       "Name: Sale_Price, Length: 2930, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best = rf_models[np.where(rf_rmse == np.min(rf_rmse))[0][0]]\n",
    "yhat_best = np.exp(rf_best.predict(x))\n",
    "pd.Series(yhat_best, name='Sale_Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={'PID': PID, 'Sale_Price': pd.Series(yhat_best, name='Sale_Price')}).to_csv('mysubmission2.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a8f1d99b810e61b75f5a34501c9775124ca753589138aace9fb33659879b761"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
