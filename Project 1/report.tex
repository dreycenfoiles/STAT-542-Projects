\documentclass{article}
\usepackage{graphicx}
\usepackage{physics}
\usepackage{float}
\usepackage{amsfonts}
\title{Project 1 Report}
\author{Dreycen Foiles, Olek Yardas}
\date{\today}
\begin{document}
\maketitle

\section{Introduction}

We report on our efforts to use different regression techniques to predict the price of a house in Ames, IA given various different parameters. The two techniques that we present in this report is the Least Absolute Shrinkage and Selection Operator (LASSO) and the Random Forest regression algorithm.
% Talk more about intro and maybe motivation 

\section{Methods}

\subsection{Data Preprocessing}
For this project, we are given a data set made up numerous data points. These
include numerical data like basement area,  lot size, number of floors, year
built, as well as categorical data like zoning type, heating type, street type.
Our goal is to use these values to predict the price of the corresponding house.
Before we can build a model, we must first clean the data in two steps:
1) remove missing and low-importance values, and 2) convert non-numerical data
into a form that can be used with our regression techniques. Our data cleaning
approach, we removed the following columns of data:
PID, Garage\_Yr\_Blt, Street, Utilities, Condition\_2, Roof\_Matl, Heating,
Pool\_QC, Misc\_Feature, Low\_Qual\_Fin\_SF, Pool\_Area, Longitude, Latitude.
For numeric data stored as strings, we used the \verb,pandas.to_numeric, 
function to convert the data into the appropriate numeric datatypes. For
categorical data, we used the common approach of creating a vector of length
$n$ with the $i$th entry being 1 and the remaining values being 0, where $n$ is
the number of different categorical values, and $i$ corresponds a particular
categorical value.

We used 90\% winsorization on the data to remove extreme values to improve performance.

\subsection{Regression algorithms}
We used the \verb.Lasso. and \verb.RandomForestRegressor. classes from the
\verb.sklearn. package to perform our regression
.


\section{Linear Model}

\subsection{Results}

\section{Random Forest}

Our random forest model appeared to work will with a simple factorize command. This is because the random forest model is nonlinear and category values of 1,2,3, etc. are not going to introduce artifacts into the prediction that it would for linear models. We used the Scikit-Learn implementation of the random forest regressor and we found that even with the default parameters, we were able to get the RMSE test error below the benchmark.

\subsection{Results}


\begin{center} 
    \begin{tabular}{ | c |  c |  c |} 
        \hline
        Split \# & RMSE & Runtime (sec.) \\ 
        \hline\hline
        1 & 0.086 & 2.361 \\ 
        \hline 
        2 & 0.087 & 2.328 \\ 
        \hline 
        3 & 0.097 & 2.335 \\ 
        \hline 
        4 & 0.093 & 2.434 \\ 
        \hline 
        5 & 0.090 & 2.451 \\ 
        \hline 
        6 & 0.087 & 2.432 \\ 
        \hline
         7 & 0.085 & 2.363 \\ 
         \hline 
        8 & 0.097 & 2.342 \\ 
        \hline 
        9 & 0.092 & 2.435 \\ 
        \hline
        10 & 0.088 & 2.422 \\ 
        \hline 
    \end{tabular} 
\end{center}

\section{Conclusion}



\end{document}
