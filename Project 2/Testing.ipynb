{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# read raw data and extract date column\n",
    "train_raw = pd.read_csv('https://liangfgithub.github.io/Data/train.csv.zip')\n",
    "\n",
    "# training data from 2010-02 to 2011-02\n",
    "start_date = pd.to_datetime('2010-02-01')\n",
    "end_date = start_date + relativedelta(months=13)\n",
    "\n",
    "# split dataset into training / testing\n",
    "train_ids = (pd.to_datetime(train_raw['Date']) >= start_date) & (pd.to_datetime(train_raw['Date']) < end_date)\n",
    "train = train_raw.loc[train_ids]\n",
    "test = train_raw.loc[~train_ids]\n",
    "\n",
    "# create the initial training data\n",
    "train.to_csv('train_ini.csv')\n",
    "\n",
    "# create test.csv\n",
    "# removes weekly sales\n",
    "test = test.drop(columns=['Weekly_Sales'])\n",
    "test.to_csv('test.csv')\n",
    "\n",
    "# create 10 time-series\n",
    "num_folds = 10\n",
    "\n",
    "# month 1 --> 2011-03, and month 20 --> 2012-10.\n",
    "# Fold 1 : month 1 & month 2, Fold 2 : month 3 & month 4 ...\n",
    "for i in range(num_folds):\n",
    "    # filter fold for dates\n",
    "    start_date = pd.to_datetime('2011-03-01') + relativedelta(months = 2 * i)\n",
    "    end_date = pd.to_datetime('2011-05-01') + relativedelta(months = 2 * i)\n",
    "    test_ids = (pd.to_datetime(test['Date']) >= start_date) & (pd.to_datetime(test['Date']) < end_date)\n",
    "    test_fold = test.loc[test_ids]\n",
    "\n",
    "    # write fold to a file\n",
    "    test_fold.to_csv('fold_{}.csv'.format(i + 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingRegressor()"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ini = pd.read_csv(\"train_ini.csv\",parse_dates=['Date'])\n",
    "dates = train_ini['Date'];\n",
    "\n",
    "train_ini['Date'] = (dates - dates.min()).dt.days\n",
    "train_ini['IsHoliday'].apply(pd.to_numeric)\n",
    "\n",
    "xdata = train_ini[['Store', 'Dept', 'Date', 'IsHoliday']].values\n",
    "ydata = train_ini['Weekly_Sales'].values\n",
    "\n",
    "boost = GradientBoostingRegressor(n_estimators=100)\n",
    "boost.fit(xdata,ydata)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foile\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Date\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2011-03-04'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_16872\\3411957666.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 30\u001B[1;33m \u001B[0mmypredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_ini\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     31\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_16872\\3411957666.py\u001B[0m in \u001B[0;36mmypredict\u001B[1;34m(train, next_fold, t)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m     \u001B[1;31m# TODO:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m     \u001B[0mypred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mboost\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m   1875\u001B[0m             \u001B[0mThe\u001B[0m \u001B[0mpredicted\u001B[0m \u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1876\u001B[0m         \"\"\"\n\u001B[1;32m-> 1877\u001B[1;33m         X = self._validate_data(\n\u001B[0m\u001B[0;32m   1878\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mDTYPE\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"C\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"csr\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1879\u001B[0m         )\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    564\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Validation should be done on X, y or both.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    565\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 566\u001B[1;33m             \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    567\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    568\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    744\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcasting\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"unsafe\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    745\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 746\u001B[1;33m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    747\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    748\u001B[0m                 raise ValueError(\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   2062\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2063\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnpt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDTypeLike\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2064\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2065\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2066\u001B[0m     def __array_wrap__(\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: '2011-03-04'"
     ]
    }
   ],
   "source": [
    "def mypredict(train, next_fold, t):\n",
    "\n",
    "    tmp = pd.DataFrame()\n",
    "\n",
    "    data_cols = ['Store', 'Dept', 'IsHoliday', 'Weekly_Sales']\n",
    "    x_cols = ['Store', 'Dept', 'IsHoliday']\n",
    "\n",
    "    if isinstance(next_fold, type(None)):\n",
    "        dates = train['Date']\n",
    "        tmp['Date'] = (dates - dates.min())\n",
    "        tmp[data_cols] = train[data_cols]\n",
    "\n",
    "    else:\n",
    "        next_fold = next_fold[data_cols]\n",
    "        tmp = pd.concat([tmp,next_fold])\n",
    "\n",
    "    xtrain = tmp[x_cols]\n",
    "    ytrain = tmp['Weekly_Sales']\n",
    "\n",
    "    boost = GradientBoostingRegressor()\n",
    "\n",
    "    boost.fit(xtrain, ytrain)\n",
    "\n",
    "    # FIXME\n",
    "    ypred = boost.predict(test)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "mypredict(train_ini, None, 0)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_ini.csv', parse_dates=['Date'])\n",
    "test = pd.read_csv('test.csv', parse_dates=['Date'])\n",
    "\n",
    "# save weighed mean absolute error WMAE\n",
    "n_folds = 10\n",
    "next_fold = None\n",
    "wae = []\n",
    "\n",
    "# time-series prediction\n",
    "for t in range(1, n_folds+1):\n",
    "    print(f'Fold{t}...')\n",
    "\n",
    "    # *** THIS IS YOUR PREDICTION FUNCTION ***\n",
    "    test_pred = mypredict(train, next_fold, t)\n",
    "\n",
    "    # Load fold file\n",
    "    # You should add this to your training data in the next call to mypredict()\n",
    "    fold_file = 'fold_{t}.csv'.format(t=t)\n",
    "    next_fold = pd.read_csv(fold_file, parse_dates=['Date'])\n",
    "\n",
    "    # extract predictions matching up to the current fold\n",
    "    scoring_df = next_fold.merge(test_pred, on=['Date', 'Store', 'Dept'], how='left')\n",
    "\n",
    "    # extract weights and convert to numpy arrays for wae calculation\n",
    "    weights = scoring_df['IsHoliday'].apply(lambda is_holiday:5 if is_holiday else 1).to_numpy()\n",
    "    actuals = scoring_df['Weekly_Sales'].to_numpy()\n",
    "    preds = scoring_df['Weekly_Pred'].fillna(0).to_numpy()\n",
    "\n",
    "    wae.append((np.sum(weights * np.abs(actuals - preds)) / np.sum(weights)).item())\n",
    "\n",
    "print(wae)\n",
    "print(sum(wae)/len(wae))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
