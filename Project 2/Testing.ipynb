{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw data and extract date column\n",
    "train_raw = pd.read_csv('https://liangfgithub.github.io/Data/train.csv.zip')\n",
    "\n",
    "# Preproccess data\n",
    "# Add classifiers for weeks, years\n",
    "yrs = pd.to_datetime(train_raw['Date']).dt.to_period('Y').unique().year\n",
    "n_years = len(yrs)\n",
    "for date in train_raw['Date'].unique():\n",
    "    wk = np.zeros(52)\n",
    "    yr = np.zeros(n_years)\n",
    "    y, m, d = date.split('-')\n",
    "    wk_idx = datetime.date(int(y), int(m), int(d)).isocalendar()[1] - 1\n",
    "    yr_idx = np.where(yrs == int(y))[0][0]\n",
    "    # it takes too long to write all the arrays to a file, so\n",
    "    # we'll just do that in memeory in the next step\n",
    "    train_raw.loc[train_raw['Date']==date,'Week'] = wk_idx\n",
    "    train_raw.loc[train_raw['Date']==date,'Year'] = yr_idx\n",
    "train_raw.Week = train_raw.Week.astype(int)\n",
    "train_raw.Year = train_raw.Year.astype(int)\n",
    "# training data from 2010-02 to 2011-02\n",
    "start_date = pd.to_datetime('2010-02-01')\n",
    "end_date = start_date + relativedelta(months=13)\n",
    "\n",
    "# split dataset into training / testing \n",
    "train_ids = (pd.to_datetime(train_raw['Date']) >= start_date) & (pd.to_datetime(train_raw['Date']) < end_date)\n",
    "train = train_raw.loc[train_ids, ]\n",
    "test = train_raw.loc[~train_ids, ]\n",
    "\n",
    "# create the initial training data\n",
    "print('exportint train_ini.csv')\n",
    "train.to_csv('train_ini.csv', index=False)\n",
    "\n",
    "# create 10 time-series\n",
    "num_folds = 10\n",
    "\n",
    "# month 1 --> 2011-03, and month 20 --> 2012-10.\n",
    "# Fold 1 : month 1 & month 2, Fold 2 : month 3 & month 4 ...\n",
    "print('Making folds')\n",
    "for i in range(num_folds):\n",
    "    # filter fold for dates\n",
    "    start_date = pd.to_datetime('2011-03-01') + relativedelta(months = 2 * i)\n",
    "    end_date = pd.to_datetime('2011-05-01') + relativedelta(months = 2 * i)\n",
    "    test_ids = (pd.to_datetime(test['Date']) >= start_date) & (pd.to_datetime(test['Date']) < end_date)\n",
    "    test_fold = test.loc[test_ids, ]\n",
    "\n",
    "# write fold to a file\n",
    "test_fold.to_csv('fold_{}.csv'.format(i + 1), index=False)\n",
    "\n",
    "# create test.csv\n",
    "# removes weekly sales\n",
    "test = test.drop(columns=['Weekly_Sales'])\n",
    "test.to_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mypredict(train, test, next_fold, t):\n",
    "\n",
    "    x_cols = ['Year', 'Week', 'Store', 'Dept', 'IsHoliday']\n",
    "\n",
    "    start_date = pd.to_datetime(\"2011-03\") + pd.DateOffset(months=2*t)\n",
    "    end_date = pd.to_datetime(\"2011-04\") + pd.DateOffset(months=2*t)\n",
    "\n",
    "    date_filter = (test['Date'] >= start_date) & (test['Date'] < end_date)\n",
    "\n",
    "    current_test = test[x_cols].copy().loc[date_filter]\n",
    "\n",
    "    #tmp = pd.DataFrame()\n",
    "\n",
    "    if not isinstance(next_fold, type(None)):\n",
    "        next_fold = next_fold\n",
    "        train = pd.concat([train,next_fold])\n",
    "\n",
    "    #dates = train['Date']\n",
    "    #tmp = train.copy()\n",
    "    #tmp['Date'] = (dates - dates.min()).dt.days\n",
    "\n",
    "    #current_test_dates = current_test['Date']\n",
    "    #current_test['Date'] = (current_test_dates - dates.min()).dt.days\n",
    "\n",
    "    xtrain = train[x_cols].values\n",
    "    ytrain = train['Weekly_Sales'].values\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    model.fit(xtrain, ytrain)\n",
    "\n",
    "    ypred = model.predict(current_test.values)\n",
    "    test_pred = pd.DataFrame({'Weekly_Pred': ypred,\n",
    "                              'Dates': datefilter})\n",
    "    test.loc[date_filter, \"Weekly_Pred\"] = ypred\n",
    "\n",
    "    return train, test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_ini.csv', parse_dates=['Date'])\n",
    "test = pd.read_csv('test.csv', parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_years = 3\n",
    "yrs = pd.to_datetime(train['Date']).dt.to_period('Y').unique().year\n",
    "for date in train['Date'].unique():\n",
    "    wk = np.zeros(52)\n",
    "    yr = np.zeros(n_years)\n",
    "    wk_idx = (train.loc[train['Date'] == date]['Week']).unique()[0]\n",
    "    yr_idx = (train.loc[train['Date'] == date]['Year']).unique()[0]\n",
    "    wk[wk_idx] = 1\n",
    "    yr[yr_idx] = 1\n",
    "    idx = train.loc[train['Date'] == date].index\n",
    "    n = len(idx)\n",
    "    s_wk = pd.Series(data=n * [wk], index=idx)\n",
    "    s_yr = pd.Series(data=n * [yr], index=idx)\n",
    "    # it takes too long to write all the arrays to a file, so\n",
    "    # we'll just do that in memeory in the next step\n",
    "    train.loc[train['Date']==date,'Week'] = s_wk\n",
    "    train.loc[train['Date']==date,'Year'] = s_yr\n",
    "    \n",
    "    \n",
    "yrs = pd.to_datetime(test['Date']).dt.to_period('Y').unique().year\n",
    "for date in test['Date'].unique():\n",
    "    wk = np.zeros(52)\n",
    "    yr = np.zeros(n_years)\n",
    "    wk_idx = (test.loc[test['Date'] == date]['Week']).unique()[0]\n",
    "    yr_idx = (test.loc[test['Date'] == date]['Year']).unique()[0]\n",
    "    wk[wk_idx] = 1\n",
    "    yr[yr_idx] = 1\n",
    "    idx = test.loc[test['Date'] == date].index\n",
    "    n = len(idx)\n",
    "    s_wk = pd.Series(data=n * [wk], index=idx)\n",
    "    s_yr = pd.Series(data=n * [yr], index=idx)\n",
    "    # it takes too long to write all the arrays to a file, so\n",
    "    # we'll just do that in memeory in the next step\n",
    "    test.loc[test['Date']==date,'Week'] = s_wk\n",
    "    test.loc[test['Date']==date,'Year'] = s_yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save weighed mean absolute error WMAE\n",
    "n_folds = 10\n",
    "next_fold = None\n",
    "wae = []\n",
    "\n",
    "# time-series prediction\n",
    "for t in range(1, n_folds+1):\n",
    "    print(f'Fold{t}...')\n",
    "\n",
    "    # *** THIS IS YOUR PREDICTION FUNCTION ***\n",
    "    train, test_pred = mypredict(train, test, next_fold, t-1)\n",
    "\n",
    "    # Load fold file\n",
    "    # You should add this to your training data in the next call to mypredict()\n",
    "    fold_file = 'fold_{t}.csv'.format(t=t)\n",
    "    next_fold = pd.read_csv(fold_file, parse_dates=['Date'])\n",
    "\n",
    "    #yrs = pd.to_datetime(next_fold['Date']).dt.to_period('Y').unique().year\n",
    "    #for date in next_fold['Date'].unique():\n",
    "    #    wk = np.zeros(52)\n",
    "    #    yr = np.zeros(n_years)\n",
    "    #    wk_idx = (next_fold.loc[next_fold['Date'] == date]['Week']).unique()[0]\n",
    "    #    yr_idx = (next_fold.loc[next_fold['Date'] == date]['Year']).unique()[0]\n",
    "    #    wk[wk_idx] = 1\n",
    "    #    yr[yr_idx] = 1\n",
    "    #    idx = next_fold.loc[next_fold['Date'] == date].index\n",
    "    #    n = len(idx)\n",
    "    #    s_wk = pd.Series(data=n * [wk], index=idx)\n",
    "    #    s_yr = pd.Series(data=n * [yr], index=idx)\n",
    "    #    # it takes too long to write all the arrays to a file, so\n",
    "    #    # we'll just do that in memeory in the next step\n",
    "    #    next_fold.loc[next_fold['Date']==date,'Week'] = s_wk\n",
    "    #    next_fold.loc[next_fold['Date']==date,'Year'] = s_yr\n",
    "\n",
    "    # extract predictions matching up to the current fold\n",
    "    scoring_df = next_fold.merge(\n",
    "     test_pred, on=['Date', 'Store', 'Dept'], how='left', suffixes=(\"\", \"_dummy\"))\n",
    "\n",
    "    scoring_df.drop_duplicates()\n",
    "\n",
    "    print(scoring_df)\n",
    "\n",
    "    # extract weights and convert to numpy arrays for wae calculation\n",
    "    weights = scoring_df['IsHoliday'].apply(\n",
    "     lambda is_holiday: 5 if is_holiday else 1).to_numpy()\n",
    "    actuals = scoring_df['Weekly_Sales'].to_numpy()\n",
    "    preds = scoring_df['Weekly_Pred'].fillna(0).to_numpy()\n",
    "\n",
    "    wae.append(\n",
    "     (np.sum(weights * np.abs(actuals - preds)) / np.sum(weights)).item())\n",
    "\n",
    "print(wae)\n",
    "print(sum(wae)/len(wae))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
